{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Use Mistral and gTTS to Create Your Personal Storyteller](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n",
    "\n",
    "\n",
    "In this project, you will learn how to use Mistral and gTTS to create your personal storyteller.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Introduction\">Introduction</a></li>\n",
    "    <li><a href=\"#What-does-this-guided-project-do?\">What does this guided project do?</a></li>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Background\">Background</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#What-is-large-language-model-(LLM)?\">What is large language model (LLM)?</a></li>\n",
    "            <li><a href=\"#What-is-Mistral?\">What is Mistral?</a></li>\n",
    "            <li><a href=\"#What-is-gTTS-(Google-Text-to-Speech)?\">What is gTTS (Google Text-to-Speech)?</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#watsonx-API-credentials-and-project_id\">watsonx API credentials and project_id</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Work-with-foundation-models-on-watsonx.ai\">Work with foundation models on watsonx.ai</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#List-available-models\">List available models</a></li>\n",
    "            <li><a href=\"#Defining-model-parameters\">Defining model parameters</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Generate-a-story-with-Mistral\">Generate a story with Mistral</a></li>\n",
    "    <li><a href=\"#Convert-the-story-to-speech\">Convert the story to speech</a></li>\n",
    "    <li><a href=\"#Save-the-audio-to-a-file\">(Optional) Save the audio to a file</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Exercises\">Exercises</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Exercise-1:-Generate-another-story\">Exercise 1: Generate another story</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Authors\">Authors</a></li>\n",
    "    <li><a href=\"#Contributors\">Contributors</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Introduction\"><a href=\"#Table-of-Contents\">Introduction</a></h2>\n",
    "\n",
    "Have you ever wanted to create engaging stories and have them read aloud naturally? By combining the power of AI story generation with text-to-speech technology, we can create an interactive storytelling experience. In this project, we'll use Mistral, a large language model, to generate creative stories based on any topic you provide, and then convert these stories into natural-sounding speech.\n",
    "\n",
    "<h2 id=\"What-does-this-guided-project-do\"><a href=\"#Table-of-Contents\">What does this guided project do?</a></h2>\n",
    "\n",
    "\n",
    "This project demonstrates how to create an AI storyteller by:\n",
    "1. Using Mistral to generate creative and informative stories based on your chosen topic\n",
    "2. Converting the generated story into speech using gTTS (Google Text-to-Speech)\n",
    "3. Playing the audio directly in your Jupyter notebook\n",
    "\n",
    "For example, you could input a topic like \"the life span of trees,\" and Mistral will create an engaging narrative about how trees grow, survive through seasons, and can live for hundreds or even thousands of years. This story will then be converted into spoken words, making it perfect for educational content, bedtime stories, or learning about any subject in an auditory format.\n",
    "\n",
    "<h2 id=\"Objectives\"><a href=\"#Table-of-Contents\">Objectives</a></h2>\n",
    "\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "- Use Mistral to generate creative stories from any given topic\n",
    "- Convert the generated text to speech using the gTTS library\n",
    "- Create an end-to-end pipeline for AI storytelling\n",
    "- Play generated audio directly in Jupyter notebooks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Background\"><a href=\"#Table-of-Contents\">Background</a></h2>\n",
    "\n",
    "<h3 id=\"What-is-large-language-model-(LLM)?\"><a href=\"#table-of-contents\">What is large language model (LLM)?</a></h3>\n",
    "\n",
    "\n",
    "[Large language models](https://www.ibm.com/topics/large-language-models?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Use+Mixtral+and+gTTS+to+create+your+personal+storyteller-v1_1738273977) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.\n",
    "\n",
    "<h3 id=\"What-is-Mistral\"><a href=\"#Table-of-Contents\">What is Mistral?</a></h3>\n",
    "\n",
    "[Mistral](https://mistral.ai/) is an open-source large language model developed by Mistral AI. It's a Mixture of Experts (MoE) model that achieves state-of-the-art performance among open-source models. Key features include:\n",
    "\n",
    "- **Powerful Performance**: Matches or exceeds the performance of much larger models on most benchmarks\n",
    "- **Efficient Architecture**: Uses a Sparse Mixture of Experts architecture, making it more efficient than traditional models\n",
    "- **Versatile Applications**: Excellent at tasks like creative writing, analysis, and storytelling\n",
    "- **Open Source**: Freely available for research and commercial use\n",
    "\n",
    "<h3 id=\"What-is-gTTS\"><a href=\"#Table-of-Contents\">What is gTTS (Google Text-to-Speech)?</a></h3>\n",
    "\n",
    "\n",
    "[gTTS (Google Text-to-Speech)](https://gtts.readthedocs.io/) is a Python library and CLI tool that interfaces with Google Translate's text-to-speech API. It offers:\n",
    "\n",
    "- **Multiple Languages**: Support for a wide variety of languages and accents\n",
    "- **Natural Sound**: High-quality, natural-sounding voice synthesis\n",
    "- **Easy Integration**: Simple Python interface for converting text to speech\n",
    "- **Format Options**: Ability to save audio in MP3 format or stream it directly\n",
    "- **Customization**: Control over speech speed and language variants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Setup\"><a href=\"#Table-of-Contents\">Setup</a></h2>\n",
    "\n",
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`ibm-watsonx-ai`](https://pypi.org/project/ibm-watsonx-ai/): `ibm-watsonx-ai` is a library that allows to work with watsonx.ai service on IBM Cloud and IBM Cloud for Data. Train, test and deploy your models as APIs for application development, share with colleagues using this python library.\n",
    "*   [`gtts`](https://pypi.org/project/gtts/): `gtts` is a library that allows to convert text to speech using Google Text-to-Speech API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Installing-required-libraries\"><a href=\"#Table-of-Contents\">Installing required libraries</a></h3>\n",
    "\n",
    "\n",
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You must run the following cell__ to install them. Please wait until it completes.\n",
    "\n",
    "This step could take **several minutes**, please be patient.\n",
    "\n",
    "**NOTE**: If you encounter any issues, please restart the kernel and run again.  You can do that by clicking the **Restart the kernel** icon.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/crvBKBOkg9aBzXZiwGEXbw/Restarting-the-Kernel.png\" width=\"100%\" alt=\"Restart kernel\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gTTS==2.5.4 | tail -n 1\n",
    "%pip install ibm-watsonx-ai==1.1.20 | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"watsonx-API-credentials-and-project_id\"><a href=\"#Table-of-Contents\">watsonx API credentials and project_id</a></h2>\n",
    "\n",
    "\n",
    "\n",
    "This section provides you with the necessary credentials to access the watsonx API.\n",
    "\n",
    "**Please note:**\n",
    "\n",
    "In this lab environment, you don't need to specify the api_key, and the project_id is pre_set as \"skills-network\", but if you want to use the model locally, you need to go to [watsonx](https://www.ibm.com/watsonx?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Use+Mixtral+and+gTTS+to+create+your+personal+storyteller-v1_1738273977) to create your own keys and id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import Credentials\n",
    "import os\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    )\n",
    "\n",
    "project_id=\"skills-network\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Work-with-foundation-models-on-watsonx.ai\"><a href=\"#Table-of-Contents\">Work with foundation models on watsonx.ai</a></h2>\n",
    "\n",
    "\n",
    "<h3 id=\"List-available-models\"><a href=\"#Table-of-Contents\">List available models</a></h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "client = APIClient(credentials)\n",
    "# GET TextModels ENUM\n",
    "client.foundation_models.TextModels\n",
    "\n",
    "# PRINT dict of Enums\n",
    "client.foundation_models.TextModels.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model_id of the model we will use for the chat.\n",
    "\n",
    "model_id = 'mistralai/mistral-large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Defining-model-parameters\"><a href=\"#Table-of-Contents\">Defining model parameters</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "\n",
    "params = {\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.MAX_NEW_TOKENS: 1000,\n",
    "}\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=model_id,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id,\n",
    "    params=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Generate-a-story-with-Mistral\"><a href=\"#Table-of-Contents\">Generate a story with Mistral</a></h2>\n",
    "\n",
    "Now we'll create a story using Mistral. We'll first define a function that takes a topic as input and returns a generated story. The function will use a carefully crafted prompt to ensure the story is engaging, educational, and appropriate for beginners.\n",
    "\n",
    "Let's test our storytelling capabilities by generating a story about a simple topic and converting it to speech.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an educational story using the Mistral model\n",
    "def generate_story(topic):\n",
    "    # Construct a detailed prompt that guides the model to:\n",
    "    # - Write for beginners\n",
    "    # - Use simple language\n",
    "    # - Include interesting facts\n",
    "    # - Keep a specific length\n",
    "    # - End with a summary\n",
    "    prompt = f\"\"\"Write an engaging and educational story about {topic} for beginners. \n",
    "            Use simple and clear language to explain basic concepts. \n",
    "            Include interesting facts and keep it friendly and encouraging. \n",
    "            The story should be around 200-300 words and end with a brief summary of what we learned. \n",
    "            Make it perfect for someone just starting to learn about this topic.\"\"\"\n",
    "    \n",
    "    # Generate text using the model with our carefully crafted prompt\n",
    "    response = model.generate_text(prompt=prompt)\n",
    "    return response\n",
    "\n",
    "# Example usage of the generate_story function\n",
    "# Here we use butterflies as a topic since it's an engaging and \n",
    "# educational subject that demonstrates the function well\n",
    "topic = \"the life cycle of butterflies\"\n",
    "story = generate_story(topic)\n",
    "print(\"Generated Story:\\n\", story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Convert-the-story-to-speech\"><a href=\"#Table-of-Contents\">Convert the story to speech</a></h2>\n",
    "\n",
    "\n",
    "Now that we have generated our story, let's convert it to speech using the gTTS (Google Text-to-Speech) library.\n",
    "We'll create an audio file in memory and play it directly in the notebook using an audio player widget.\n",
    "\n",
    "This step may take a while to complete, please be patient.\n",
    "\n",
    "**NOTE**: If you encounter any issues, please run the cell again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from IPython.display import Audio\n",
    "import io\n",
    "\n",
    "# Initialize text-to-speech with the generated story\n",
    "tts = gTTS(story)\n",
    "\n",
    "# Save the audio to a bytes buffer in memory\n",
    "audio_bytes = io.BytesIO()\n",
    "tts.write_to_fp(audio_bytes)\n",
    "audio_bytes.seek(0)\n",
    "\n",
    "# Create and display an audio player widget in the notebook\n",
    "Audio(audio_bytes.read(), autoplay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Save-the-audio-to-a-file\"><a href=\"#Table-of-Contents\">(Optional) Save the audio to a file</a></h2>\n",
    "\n",
    "\n",
    "```python\n",
    "# Save as MP3 file\n",
    "tts.save(\"generated_story.mp3\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Exercises\"><a href=\"#Table-of-Contents\">Exercises</a></h2>\n",
    "\n",
    "<h3 id=\"Exercise-1:-Generate-another-story\"><a href=\"#Table-of-Contents\">Exercise 1: Generate another story</a></h3>\n",
    "\n",
    "\n",
    "Please generate another story with the following topic.\n",
    "\n",
    "topic = \"the life cycle of a human\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution\n",
    "    </summary>\n",
    "\n",
    "```python\n",
    "topic = \"the life cycle of a human\"\n",
    "story = generate_story(topic)\n",
    "print(\"Generated Story:\\n\", story)\n",
    "\n",
    "# Initialize text-to-speech with the generated story\n",
    "tts = gTTS(story)\n",
    "\n",
    "audio_bytes = io.BytesIO()\n",
    "tts.write_to_fp(audio_bytes)\n",
    "audio_bytes.seek(0)\n",
    "\n",
    "# Create and display an audio player widget in the notebook\n",
    "Audio(audio_bytes.read(), autoplay=True)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Authors\"><a href=\"#Table-of-Contents\">Authors</a></h2>\n",
    "\n",
    "\n",
    "[Ricky Shi](https://author.skills.network/instructors/ricky_shi)\n",
    "\n",
    "<h2 id=\"Contributors\"><a href=\"#Table-of-Contents\">Contributors</a></h2>\n",
    "\n",
    "[Hailey Quach](https://www.haileyq.com/)\n",
    "\n",
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo)\n",
    "\n",
    "```{|Date (YYYY-MM-DD)|Version|Changed By|Change Description||-|-|-|-||2025-01-30|1.0|Ricky Shi|Create project|}\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "5658faac9a02d4a861963d2122027512014b9c39e63d6ecd31ea5a48d00b8772"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
